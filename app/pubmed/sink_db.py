"""
Allows dumping data into SQLite to speed up iteration
over the ~33 million records.
"""
import math
from typing import Optional

import atomics
import neo4j
from app.pubmed.model import Article, DBMetadata
from config import NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE


class IdCounter:
    """ Increments IDs to use for database nodes. """
    id: atomics.atomic = atomics.atomic(width=4, atype=atomics.INT)

    def __init__(self, initial_id: int = None):
        if initial_id is not None:
            self.id.store(initial_id)

    def next(self) -> int:
        return self.id.fetch_inc()


class PubmedCacheConn:
    """
    Can be used to connect to the pubmed cache Neo4J database.
    """
    def __init__(self, database: Optional[str] = None, *, reset_on_connect: bool = False):
        self.database: str = database if database is not None else NEO4J_DATABASE
        self.driver: Optional[neo4j.Driver] = None
        self.reset_on_connect: bool = reset_on_connect

        # We store metadata about the database within a Metadata node.
        self.metadata: Optional[DBMetadata] = None

        # We maintain our own counters for the IDs of authors and articles,
        # as we cannot trust the IDs generated by Neo4J as they can change.
        self.author_id_counter: Optional[IdCounter] = None
        self.article_id_counter: Optional[IdCounter] = None

    def __enter__(self):
        if self.driver is not None:
            raise ValueError("Already created connection!")

        self.driver = neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

        # Create a default connection first to create the database.
        with self.driver.session() as session:
            if self.reset_on_connect:
                session.run("CREATE OR REPLACE DATABASE {}".format(self.database)).consume()
            else:
                session.run("CREATE DATABASE {} IF NOT EXISTS".format(self.database)).consume()

        # Create a connection to the database to create its constraints and grab metadata.
        with self.new_session() as session:
            self._create_constraints(session)
            self._fetch_metadata(session)

        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.driver is None:
            return

        self.driver.close()
        self.driver = None

    def new_session(self) -> neo4j.Session:
        return self.driver.session(database=self.database)

    def _create_constraints(self, session: neo4j.Session):
        """
        This method creates all the constraints required for the database.
        Uniqueness constraints implicitly create an index for the constraint as well.
        """

        # Metadata.
        session.run(
            "CREATE CONSTRAINT metadata_constraint IF NOT EXISTS "
            "FOR (a:DBMetadata) REQUIRE a.id is UNIQUE"
        ).consume()

        # Authors.
        session.run(
            "CREATE CONSTRAINT unique_author_names IF NOT EXISTS "
            "FOR (a:Author) REQUIRE a.full_name IS UNIQUE"
        ).consume()
        session.run(
            "CREATE CONSTRAINT unique_author_ids IF NOT EXISTS "
            "FOR (a:Author) REQUIRE a.id IS UNIQUE"
        ).consume()

        # Articles.
        session.run(
            "CREATE CONSTRAINT unique_article_ids IF NOT EXISTS "
            "FOR (a:Article) REQUIRE a.id IS UNIQUE"
        ).consume()

    def _fetch_metadata(self, session: neo4j.Session):
        """
        Fetches the values to use for the author and article counters from the database.
        """
        self.author_id_counter = IdCounter(self._fetch_max_id(session, "Author") + 1)
        self.article_id_counter = IdCounter(self._fetch_max_id(session, "Article") + 1)

    def _fetch_max_id(self, session: neo4j.Session, label: str) -> int:
        """
        Fetches the maximum ID of any nodes matching the given label, or 0 if no nodes could be found.
        """
        result = session.run(
            """
            MATCH (n:{})
            RETURN max(n.id)
            """.format(label)
        ).single()[0]

        # If there are no nodes, then None will be returned.
        return 0 if result is None else result

    def insert_article_batch(self, articles: list[Article], *, max_batch_size=16000):
        """
        Inserts a batch of articles into the database, including their authors.
        """
        if len(articles) == 0:
            return

        # We batch the articles as otherwise we can hit maximum memory issues with Neo4J...
        required_batches = (len(articles) + max_batch_size - 1) // max_batch_size
        articles_per_batch = (len(articles) + required_batches - 1) // required_batches
        total_articles_inserted = 0
        for batch_no in range(required_batches):
            start_index = batch_no * articles_per_batch
            end_index = len(articles) if batch_no == required_batches - 1 else (batch_no + 1) * articles_per_batch
            batch = articles[start_index:end_index]
            total_articles_inserted += len(batch)
            with self.new_session() as session:
                session.write_transaction(self._insert_article_batch, batch)

        # Just to be sure...
        assert total_articles_inserted == len(articles)

    def _insert_article_batch(self, tx: neo4j.Transaction, articles: list[Article]):
        """
        Inserts a batch of articles into the database, including their authors.
        """
        articles_data = []
        for article in articles:
            authors_data = []
            for author in article.authors:
                authors_data.append({
                    "id": self.author_id_counter.next(),
                    "full_name": author.full_name,
                    "is_collective": author.is_collective
                })

            articles_data.append({
                "id": self.article_id_counter.next(),
                "title": article.title,
                "authors": authors_data
            })

        tx.run(
            """
            UNWIND $articles AS article
                CALL {
                    WITH article
                    CREATE (article_node:Article {id: article.id, title: article.title})
                    RETURN article_node
                }

            UNWIND article.authors AS author
                CALL {
                    WITH author
                    MERGE (author_node:Author {full_name: author.full_name})
                    ON CREATE
                        SET
                            author_node.id = author.id,
                            author_node.is_collective = author.is_collective
                    RETURN author_node
                }
                CREATE (author_node)-[:AUTHOR_OF]->(article_node)
            """,
            articles=articles_data
        ).consume()
